{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7077a7f1-84e2-48de-94e0-086233f79be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def open_image(image_path,ncdf_layer='fsc'):\n",
    "    \"\"\"Opens an image and reads its metadata.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image_path : str\n",
    "        path to an image\n",
    "    ncdf_layer: optional , string of the name of wich layer of ncdf to open      \n",
    "    Returns\n",
    "    -------\n",
    "    image : osgeo.gdal.Dataset\n",
    "        the opened image\n",
    "    information : dict\n",
    "        dictionary containing image metadata    \n",
    "    \"\"\"\n",
    "    \n",
    "    ext = os.path.basename(image_path).split('.')[-1]\n",
    "    \n",
    "    if ext == 'nc':\n",
    "        nc_data = netCDF4.Dataset(image_path,'r')\n",
    "        vars_nc = list(nc_data.variables)\n",
    "       # ncdf_layer=\"fsc_unc\"\n",
    "        scf_name = list(filter(lambda x: x.startswith(ncdf_layer), vars_nc))[0]        \n",
    "        dataset = gdal.Open(\"NETCDF:{0}:{1}\".format(image_path, scf_name))\n",
    "        proj = dataset.GetProjection()        \n",
    "        geotransform = dataset.GetGeoTransform()\n",
    "        cols = dataset.RasterXSize\n",
    "        rows = dataset.RasterYSize\n",
    "        minx = geotransform[0]\n",
    "        maxy = geotransform[3]\n",
    "        maxx = minx + geotransform[1] * cols\n",
    "        miny = maxy + geotransform[5] * rows        \n",
    "        extent = [minx, miny, maxx, maxy]        \n",
    "        X_Y_raster_size = [cols, rows]\n",
    "        information = {}\n",
    "        information['geotransform'] = geotransform\n",
    "        information['extent'] = extent\n",
    "        information['geotransform'] = tuple(map(lambda x: round(x, 4) or x, information['geotransform']))\n",
    "        information['extent'] = tuple(map(lambda x: round(x, 4) or x, information['extent'])) \n",
    "        information['X_Y_raster_size'] = X_Y_raster_size\n",
    "        information['projection'] = proj\n",
    "        \n",
    "        image_output = np.array(dataset.ReadAsArray(0, 0,cols, rows))            \n",
    "\n",
    "    else:\n",
    "        image = gdal.Open(image_path)\n",
    "        cols = image.RasterXSize\n",
    "        rows = image.RasterYSize\n",
    "        geotransform = image.GetGeoTransform()\n",
    "        proj = image.GetProjection()\n",
    "        minx = geotransform[0]\n",
    "        maxy = geotransform[3]\n",
    "        maxx = minx + geotransform[1] * cols\n",
    "        miny = maxy + geotransform[5] * rows\n",
    "        X_Y_raster_size = [cols, rows]\n",
    "        extent = [minx, miny, maxx, maxy]\n",
    "        information = {}\n",
    "        information['geotransform'] = geotransform\n",
    "        information['extent'] = extent\n",
    "        information['X_Y_raster_size'] = X_Y_raster_size\n",
    "        information['projection'] = proj\n",
    "        projection= osr.SpatialReference(wkt=image.GetProjection())\n",
    "        with rasterio.open(image_path, 'r+') as rds:\n",
    "            epsg_code = str(rds.crs).split(':')[1]\n",
    "        information['EPSG'] = epsg_code\n",
    "        #print(cols,rows )\n",
    "        image_output = np.array(image.ReadAsArray(0, 0,cols, rows))\n",
    "        \n",
    "    if image is None:\n",
    "        print('could not open ' + image_path)\n",
    "        return\n",
    "        \n",
    "    return image_output, information\n",
    "\n",
    "\n",
    "\n",
    "def get_sensor(acquisition_name):\n",
    "    \"\"\"Determines the satellite mission based on the acquisition name.\"\"\"\n",
    "    acquisition_name = os.path.basename(acquisition_name)\n",
    "    if 'LT04' in acquisition_name:\n",
    "        return 'L4'\n",
    "    elif 'LT05' in acquisition_name or acquisition_name[:3] == 'LT5':\n",
    "        return 'L5'\n",
    "    elif 'LE07' in acquisition_name or acquisition_name[:3] == 'LE7':\n",
    "        return 'L7'\n",
    "    elif 'LC08' in acquisition_name or acquisition_name[:3] == 'LC8':\n",
    "        return 'L8'\n",
    "    elif 'LC09' in acquisition_name:\n",
    "        return 'L8'\n",
    "    elif 'S2' in acquisition_name:\n",
    "        return 'S2'\n",
    "    elif 'PRS' in acquisition_name:\n",
    "        return 'PRISMA'\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid acquisition name: {acquisition_name}\")\n",
    "\n",
    "\n",
    "def plot_valid_pixels_percentage(ranges, percentage_per_angles_list, svm_folder_path):\n",
    "    \"\"\"\n",
    "    Plots the percentage of valid pixels per angle range and saves the plot as a PNG file.\n",
    "\n",
    "    Parameters:\n",
    "    - ranges (tuple of tuples): Angle ranges for the x-axis.\n",
    "    - percentage_per_angles_list (list): Percentage values corresponding to the ranges.\n",
    "    - svm_folder_path (str): Directory to save the plot.\n",
    "    \"\"\"\n",
    "    # Ensure ranges and percentage lists match\n",
    "    if len(ranges) != len(percentage_per_angles_list):\n",
    "        raise ValueError(\"Length of ranges and percentage_per_angles_list must match.\")\n",
    "    \n",
    "    # Create the bar plot\n",
    "    x_labels = [f\"{r[0]}-{r[1]}\" for r in ranges]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(x_labels, percentage_per_angles_list, color='skyblue')\n",
    "    \n",
    "    # Add title and labels\n",
    "    plt.title(\"Percentage of Valid Pixels per Solar Incidence Angle Range\", fontsize=14)\n",
    "    plt.xlabel(\"Angle Ranges (degrees)\", fontsize=12)\n",
    "    plt.ylabel(\"Percentage (%)\", fontsize=12)\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Save the plot\n",
    "    output_path = os.path.join(svm_folder_path, 'valid_pixels_per_angle.png')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()  # Close the plot to avoid display issues in non-interactive environments\n",
    "    print(f\"Plot saved to: {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_representative_pixels(bands_data, valid_mask, sample_count = 50, k='auto', n_closest='auto'):\n",
    "    \"\"\"\n",
    "    Selects representative \"no snow\" pixels by clustering and distance to cluster centroids.\n",
    "    Saves the output as a raster.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bands_data : numpy.ndarray\n",
    "        3D array (bands, height, width) containing spectral data for each band.\n",
    "    valid_mask : numpy.ndarray\n",
    "        2D mask of valid pixels for selection.\n",
    "    k : int, optional\n",
    "        Number of clusters for K-means, by default 5.\n",
    "    n_closest : int, optional\n",
    "        Number of closest pixels to each centroid to select, by default 5.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    representative_pixels_mask : numpy.ndarray\n",
    "        2D mask with representative pixels marked as 1.\n",
    "    \"\"\"\n",
    "    # Extract \"valid\" pixels for clustering\n",
    "    valid_pixels = bands_data[valid_mask, :]  # Shape (pixels, bands)\n",
    "\n",
    "    # Normalize the valid pixels\n",
    "    scaler = StandardScaler()\n",
    "    normalized_pixels = scaler.fit_transform(valid_pixels)\n",
    "    \n",
    "    # find optimal K\n",
    "    if k == 'auto':\n",
    "        k = find_optimal_k(normalized_pixels, max_k=10, method=\"elbow\")\n",
    "    if n_closest == 'auto':\n",
    "        n_closest = int(sample_count / k)\n",
    "\n",
    "    # Perform K-means clustering on \"no snow\" pixels\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(normalized_pixels)\n",
    "\n",
    "    # Get cluster centroids and labels\n",
    "    labels = kmeans.labels_\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    # Initialize an empty mask for representative pixels\n",
    "    representative_pixels_mask = np.zeros(valid_mask.shape, dtype='uint8')\n",
    "\n",
    "    # Find the n_closest pixels to each centroid\n",
    "    for cluster_idx in range(k):\n",
    "        # Select pixels in the current cluster\n",
    "        cluster_indices = np.where(labels == cluster_idx)[0]\n",
    "        cluster_pixels = normalized_pixels[cluster_indices]\n",
    "\n",
    "        # Compute distances to the centroid for these pixels\n",
    "        distances = distance.cdist(cluster_pixels, [centroids[cluster_idx]], 'euclidean').flatten()\n",
    "\n",
    "        # Get the indices of the n_closest pixels in the cluster\n",
    "        closest_indices = np.argsort(distances)[:n_closest]\n",
    "\n",
    "        # Map the closest indices back to the original image coordinates\n",
    "        original_indices = np.argwhere(valid_mask)[cluster_indices]\n",
    "        selected_pixels = original_indices[closest_indices]\n",
    "\n",
    "        # Set these pixels in the representative mask\n",
    "        representative_pixels_mask[selected_pixels] = 1\n",
    "\n",
    "    return representative_pixels_mask\n",
    "\n",
    "\n",
    "\n",
    "def read_masked_values(geotiff_path, mask, bands=None):\n",
    "    \"\"\"\n",
    "    Reads the values of a multispectral GeoTIFF corresponding to a logical mask.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    geotiff_path : str\n",
    "        Path to the GeoTIFF file.\n",
    "    mask : numpy.ndarray\n",
    "        A 2D boolean mask (True where you want to keep values, False otherwise).\n",
    "    bands : list of int, optional\n",
    "        List of band indices to read (1-based index). If None, all bands are read.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    masked_values : numpy.ndarray\n",
    "        2D array of values where each row contains the pixel values across bands \n",
    "        for locations where the mask is True.\n",
    "    \"\"\"\n",
    "    with rasterio.open(geotiff_path) as src:\n",
    "        # If bands are not specified, read all bands\n",
    "        if bands is None:\n",
    "            bands = list(range(1, src.count + 1))\n",
    "        \n",
    "        # List to store masked values for each band\n",
    "        masked_values_per_band = []\n",
    "\n",
    "        for band in bands:\n",
    "            data = src.read(band)  # Read each specified band\n",
    "            masked_values_per_band.append(data[mask])  # Apply mask and store result\n",
    "\n",
    "        # Stack the results to create a 2D array with shape (num_pixels, num_bands)\n",
    "        masked_values = np.stack(masked_values_per_band, axis=-1)\n",
    "\n",
    "    return masked_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba9d40c-a3d5-4ad8-b65a-a4f3368a7713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a551f9d9-984b-4abc-981a-3b0bdcfc3168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_trainings(curr_acquisition, curr_aux_folder, auxiliary_folder_path, SVM_folder_name, no_data_mask, bands, PCA=False, total_samples = 500):\n",
    "    \n",
    "    scf_folder = os.path.join(curr_acquisition, SVM_folder_name)\n",
    "    if not os.path.exists(scf_folder):\n",
    "        os.makedirs(scf_folder)\n",
    "        \n",
    "    sensor = get_sensor(os.path.basename(curr_acquisition))\n",
    "    \n",
    "    path_cloud_mask = glob.glob(os.path.join(curr_aux_folder, '*cloud_Mask.tif'))[0]\n",
    "    path_water_mask = glob.glob(os.path.join(auxiliary_folder_path, '*Water_Mask.tif'))[0]\n",
    "    solar_incidence_angle_path = glob.glob(os.path.join(curr_aux_folder, '*solar_incidence_angle.tif'))[0]\n",
    "    NDSI_path = glob.glob(os.path.join(curr_aux_folder, '*NDSI.tif'))[0]\n",
    "    NDVI_path = glob.glob(os.path.join(curr_aux_folder, '*NDVI.tif'))[0]\n",
    "    diff_B_NIR_path = glob.glob(os.path.join(curr_aux_folder, '*diffBNIR.tif'))[0]\n",
    "    shad_idx_path = glob.glob(os.path.join(curr_aux_folder, '*shad_idx.tif'))[0]\n",
    "    distance_index_path = glob.glob(os.path.join(curr_aux_folder, '*distance.tif'))[0]\n",
    "        \n",
    "    \n",
    "    bands_path = glob.glob(os.path.join(curr_acquisition, '*scf.vrt'))\n",
    "    \n",
    "    if bands_path == []:\n",
    "        bands_path = [f for f in glob.glob(curr_acquisition + os.sep + \"PRS*.tif\") if 'PCA' not in f][0]\n",
    "    else:\n",
    "        bands_path = bands_path[0]\n",
    "        \n",
    "    valid_mask = np.logical_not(no_data_mask)\n",
    "    \n",
    "    # Load masks and other necessary data\n",
    "    cloud_mask = open_image(path_cloud_mask)[0]\n",
    "    water_mask = open_image(path_water_mask)[0]\n",
    "    solar_incidence_angle = open_image(solar_incidence_angle_path)[0]\n",
    "    curr_scene_valid = np.logical_not(np.logical_or.reduce((cloud_mask == 2, water_mask == 1, no_data_mask)))\n",
    "    \n",
    "    ranges = ((0,20), (20, 45), (45, 70), (70, 90), (90, 180))\n",
    "    range_samples = calculate_training_samples(solar_incidence_angle, ranges, total_samples)\n",
    "    #ranges = ((70, 90))\n",
    "    \n",
    "    #ranges = ((0,20), (20, 30), (30, 40), (40, 50), (50, 60), (60, 70), (70, 80), (80, 90), (90, 180))\n",
    "    empty = np.zeros(curr_scene_valid.shape, dtype='uint8')\n",
    "    \n",
    "    percentage_per_angles_list = []\n",
    "    for curr_range, sample_count in range_samples.items():\n",
    "        print(curr_range)\n",
    "        print(sample_count)\n",
    "        \n",
    "        # Initialize as empty arrays\n",
    "        representative_pixels_mask_snow = np.array([])\n",
    "        representative_pixels_mask_noSnow = np.array([])\n",
    "    \n",
    "        curr_angle_valid = np.logical_and(curr_scene_valid, np.logical_and(solar_incidence_angle >= curr_range[0], solar_incidence_angle < curr_range[1]))\n",
    "        \n",
    "        percentage_of_scene_valid =  np.sum(curr_angle_valid) / np.sum(curr_scene_valid)\n",
    "        \n",
    "        percentage_per_angles_list.append(percentage_of_scene_valid)\n",
    "    \n",
    "        curr_NDSI = read_masked_values(NDSI_path, curr_angle_valid)\n",
    "        curr_NDVI = read_masked_values(NDVI_path, curr_angle_valid)\n",
    "        curr_green = read_masked_values(bands_path, curr_angle_valid, bands=[2])\n",
    "        curr_bands = read_masked_values(bands_path, curr_angle_valid)\n",
    "        curr_diff_B_NIR = read_masked_values(diff_B_NIR_path, curr_angle_valid)\n",
    "        curr_shad_idx = read_masked_values(shad_idx_path, curr_angle_valid)\n",
    "        curr_distance_idx = read_masked_values(distance_index_path, curr_angle_valid)\n",
    "    \n",
    "        # SNOW TRAINING\n",
    "        if curr_range[0] >= 90:\n",
    "            # Normalize indices and compute shadow metric\n",
    "            diff_B_NIR_low_perc, diff_B_NIR_high_perc = np.percentile(curr_diff_B_NIR, [2, 95])\n",
    "            shad_idx_low_perc, shad_idx_high_perc = np.percentile(curr_shad_idx, [2, 95])\n",
    "            curr_diff_B_NIR_norm = np.clip((curr_diff_B_NIR - diff_B_NIR_low_perc) / (diff_B_NIR_high_perc - diff_B_NIR_low_perc), 0, 1)\n",
    "            curr_shad_idx_norm = np.clip((curr_shad_idx - shad_idx_low_perc) / (shad_idx_high_perc - shad_idx_low_perc), 0, 1)\n",
    "            curr_score_snow_shadow = curr_diff_B_NIR_norm - curr_shad_idx_norm\n",
    "            threshold_shadow = np.percentile(curr_score_snow_shadow, 95)\n",
    "            curr_valid_snow_mask_shadow = np.logical_and.reduce((curr_score_snow_shadow >= threshold_shadow, curr_NDSI > 0.7, curr_distance_idx != 255)).flatten()\n",
    "            if np.sum(curr_valid_snow_mask_shadow) > 10:\n",
    "                representative_pixels_mask_snow = get_representative_pixels(curr_bands, curr_valid_snow_mask_shadow, sample_count = int(sample_count/2), k=5, n_closest='auto')\n",
    "        else:\n",
    "            # Normalize indices and compute sun metric\n",
    "            NDSI_low_perc, NDSI_high_perc = np.percentile(curr_NDSI[np.logical_not(np.isnan(curr_NDSI))], [1, 99])\n",
    "            NDVI_low_perc, NDVI_high_perc = np.percentile(curr_NDVI[np.logical_not(np.isnan(curr_NDVI))], [1, 99])\n",
    "            green_low_perc, green_high_perc = np.percentile(curr_green, [1, 99])\n",
    "            curr_NDSI_norm = np.clip((curr_NDSI - NDSI_low_perc) / (NDSI_high_perc - NDVI_low_perc), 0, 1)\n",
    "            curr_NDVI_norm = np.clip((curr_NDVI - NDVI_low_perc) / (NDVI_high_perc - NDVI_low_perc), 0, 1)\n",
    "            curr_green_norm = np.clip((curr_green - green_low_perc) / (green_high_perc - green_low_perc), 0, 1)\n",
    "            curr_score_snow_sun = curr_NDSI_norm - curr_NDVI_norm + curr_green_norm\n",
    "            threshold = np.percentile(curr_score_snow_sun, 95)\n",
    "            curr_valid_snow_mask = np.logical_and.reduce((curr_score_snow_sun >= threshold, curr_NDSI > 0.7, curr_distance_idx != 255)).flatten()\n",
    "            \n",
    "            if np.sum(curr_valid_snow_mask) > 10:\n",
    "                representative_pixels_mask_snow = get_representative_pixels(curr_bands, curr_valid_snow_mask, sample_count = int(sample_count/2), k=5, n_closest='auto')\n",
    "    \n",
    "        ## NO snow TRAINING\n",
    "        if curr_range[0] >= 90:\n",
    "            threshold_shadow_no_snow = np.percentile(curr_score_snow_shadow, 5)\n",
    "            curr_valid_no_snow_mask_shadow = (curr_score_snow_shadow <= threshold_shadow_no_snow).flatten()\n",
    "            \n",
    "            if np.sum(curr_valid_no_snow_mask_shadow) > 10:\n",
    "                representative_pixels_mask_noSnow = get_representative_pixels(curr_bands, curr_valid_no_snow_mask_shadow, sample_count = int(sample_count/2), k=5, n_closest='auto') * 2\n",
    "        else:\n",
    "            curr_valid_no_snow_mask = (curr_NDSI < 0).flatten()\n",
    "            \n",
    "            if np.sum(curr_valid_no_snow_mask) > 10:\n",
    "                representative_pixels_mask_noSnow = get_representative_pixels(curr_bands, curr_valid_no_snow_mask, sample_count = int(sample_count/2), k=10, n_closest='auto') * 2\n",
    "    \n",
    "        # Check if masks have been assigned; if not, set as zeros\n",
    "        if representative_pixels_mask_snow.size == 0:\n",
    "            representative_pixels_mask_snow = np.zeros(curr_angle_valid.sum(), dtype='uint8')\n",
    "        if representative_pixels_mask_noSnow.size == 0:\n",
    "            representative_pixels_mask_noSnow = np.zeros(curr_angle_valid.sum(), dtype='uint8')\n",
    "            \n",
    "        representative_pixels_mask = representative_pixels_mask_noSnow + representative_pixels_mask_snow\n",
    "        empty[curr_angle_valid] = representative_pixels_mask\n",
    "        \n",
    "        print(str(np.sum(representative_pixels_mask_snow.flatten())) + ' SNOW PIXELS')\n",
    "        print(str(np.sum(representative_pixels_mask_noSnow.flatten() / 2)) + ' NO SNOW PIXELS')\n",
    "\n",
    "    \n",
    "    # Convert points where result == 1 or 2 to a shapefile\n",
    "    points = []\n",
    "    values = []\n",
    "    with rasterio.open(NDSI_path) as src:\n",
    "        for row, col in zip(*np.where((empty == 1) | (empty == 2))):\n",
    "            x, y = src.xy(row, col)\n",
    "            points.append(Point(x, y))\n",
    "            values.append(empty[row, col])\n",
    "\n",
    "    gdf = gpd.GeoDataFrame({\"value\": values}, geometry=points, crs=src.crs)\n",
    "    svm_folder_path = os.path.join(curr_acquisition, SVM_folder_name)\n",
    "    \n",
    "    plot_valid_pixels_percentage(ranges, percentage_per_angles_list, svm_folder_path)\n",
    "    \n",
    "    shapefile_path = os.path.join(svm_folder_path, 'representative_pixels_for_training_samples.shp')\n",
    "    gdf.to_file(shapefile_path, driver=\"ESRI Shapefile\")\n",
    "    \n",
    "    training_mask_path = os.path.join(svm_folder_path, 'representative_pixels_for_training_samples.tif')\n",
    "    \n",
    "    # Update the profile and save the representative mask\n",
    "    with rasterio.open(NDSI_path) as src:\n",
    "        profile = src.profile\n",
    "    profile.update(dtype='uint8', count=1, compress='lzw', nodata=0)\n",
    "    \n",
    "    with rasterio.open(training_mask_path, 'w', **profile) as dst:\n",
    "        dst.write(empty, 1)\n",
    "\n",
    "    return shapefile_path , training_mask_path   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
